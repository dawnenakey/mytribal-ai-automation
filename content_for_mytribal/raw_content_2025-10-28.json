[
  {
    "title": "PayPal partners with OpenAI to let users pay for their shopping within ChatGPT",
    "link": "https://techcrunch.com/2025/10/28/paypal-partners-with-openai-to-let-users-pay-for-their-shopping-within-chatgpt/",
    "summary": "Paypal said on Tuesday that it is adopting a protocol in combination with OpenAI's \"Instant Checkout\" feature to let users pay for their shopping directly within ChatGPT, starting in 2026.",
    "published": "Tue, 28 Oct 2025 10:47:43 +0000",
    "source_name": "tech_crunch",
    "source_url": "https://techcrunch.com/feed/",
    "category": "tech_news",
    "weight": 0.9,
    "ai_relevance_score": 0.8,
    "timestamp": "2025-10-28T09:00:02.285173",
    "ready_for_mytribal": true,
    "parsed_date": null,
    "days_old": 999,
    "priority_score": 0.7200000000000001
  },
  {
    "title": "OpenAI offers free ChatGPT Go for one year to all users in India",
    "link": "https://techcrunch.com/2025/10/27/openai-offers-free-chatgpt-go-for-one-year-to-all-users-in-india/",
    "summary": "ChatGPT Go is now free for Indian users under a limited-time promotional offer.",
    "published": "Tue, 28 Oct 2025 06:17:09 +0000",
    "source_name": "tech_crunch",
    "source_url": "https://techcrunch.com/feed/",
    "category": "tech_news",
    "weight": 0.9,
    "ai_relevance_score": 0.8,
    "timestamp": "2025-10-28T09:00:02.285325",
    "ready_for_mytribal": true,
    "parsed_date": null,
    "days_old": 999,
    "priority_score": 0.7200000000000001
  },
  {
    "title": "Intuit learned to build AI agents for finance the hard way: Trust lost in buckets, earned back in spoonfuls",
    "link": "https://venturebeat.com/ai/intuit-learned-to-build-ai-agents-for-finance-the-hard-way-trust-lost-in",
    "summary": "<p>Building AI for financial software requires a different playbook than consumer AI, and <a href=\"https://www.intuit.com/\"><u>Intuit&#x27;s</u></a> latest QuickBooks release provides an example.</p><p>The company has announced Intuit Intelligence, a system that orchestrates specialized AI agents across its QuickBooks platform to handle tasks including sales tax compliance and payroll processing. These new agents augment existing accounting and project management agents (which have also been updated) as well as a unified interface that lets users query data across QuickBooks, third-party systems and uploaded files using natural language. </p><p>The new development follow years of investment and improvement in Intuit&#x27;s<a href=\"https://venturebeat.com/ai/inside-intuits-genos-update-why-prompt-optimization-and-intelligent-data-cognition-are-critical-to-enterprise-agentic-ai-success\"> <u>GenOS</u></a>, allowing the company to build AI capabilities that reduce<a href=\"https://venturebeat.com/ai/how-intuit-built-custom-financial-llms-that-cut-latency-50-while-boosting\"> <u>latency and improve accuracy</u></a>.</p><p>But the real news isn&#x27;t what Intuit built — it&#x27;s how they built it and why their design decisions will make AI more usable. The company&#x27;s latest AI rollout represents an evolution built on hard-won lessons about what works and what doesn&#x27;t when deploying AI in financial contexts.</p><p>What the company learned is sobering: Even when its accounting agent improved transaction categorization accuracy by 20 percentage points on average, they still received complaints about errors.</p><p>&quot;The use cases that we&#x27;re trying to solve for customers include tax and finance; if you make a mistake in this world, you lose trust with customers in buckets and we only get it back in spoonfuls,&quot; Joe Preston, Intuit&#x27;s VP of product and design, told VentureBeat.</p><h2>The architecture of trust: Real data queries over generative responses</h2><p>Intuit&#x27;s technical strategy centers on a fundamental design decision. For financial queries and business intelligence, the system queries actual data, rather than generating responses through large language models (LLMs).</p><p>A<!-- -->lso critically important: That data isn&#x27;t all in one place. Intuit&#x27;s technical implementation allows QuickBooks to ingest data from multiple distinct sources: native Intuit data, OAuth-connected third-party systems like Square for payments and user-uploaded files such as spreadsheets containing vendor pricing lists or marketing campaign data. This creates a unified data layer that AI agents can query reliably.</p><p>&quot;We&#x27;re actually querying your real data,&quot; Preston explained. &quot;That&#x27;s very different than if you were to just copy, paste out a spreadsheet or a PDF and paste into ChatGPT.&quot;</p><p>This architectural choice means that the Intuit Intelligence system functions more as an orchestration layer. It&#x27;s a natural language interface to structured data operations. When a user asks about projected profitability or wants to run payroll, the system translates the natural language query into database operations against verified financial data.</p><p>This matters because Intuit&#x27;s internal research has uncovered widespread shadow AI usage. When surveyed, 25% of accountants using QuickBooks admitted they were already copying and pasting data into ChatGPT or Google Gemini for analysis.</p><p>Intuit&#x27;s approach treats AI as a query translation and orchestration mechanism, not a content generator. This reduces the hallucination risk that has plagued AI deployments in financial contexts.</p><h2>Explainability as a design requirement, not an afterthought</h2><p>Beyond the technical architecture, Intuit has made explainability a core user experience across its AI agents. This goes beyond simply providing correct answers: It means showing users the reasoning behind automated decisions.</p><p>When Intuit&#x27;s accounting agent categorizes a transaction, it doesn&#x27;t just display the result; it shows the reasoning. This isn&#x27;t marketing copy about explainable AI, it&#x27;s actual UI displaying data points and logic.</p><p>&quot;It&#x27;s about closing that trust loop and making sure customers understand the why,&quot; Alistair Simpson, Intuit&#x27;s VP of design, told VentureBeat.</p><p>This becomes particularly critical when you consider Intuit&#x27;s user research: While half of small businesses describe AI as helpful, nearly a quarter haven&#x27;t used AI at all. The explanation layer serves both populations: Building confidence for newcomers, while giving experienced users the context to verify accuracy.</p><p>The design also enforces human control at critical decision points. This approach extends beyond the interface. Intuit connects users directly with human experts, embedded in the same workflows, when automation reaches its limits or when users want validation.</p><h2>Navigating the transition from forms to conversations</h2><p>One of Intuit&#x27;s more interesting challenges involves managing a fundamental shift in user interfaces. Preston described it as having one foot in the past and one foot in the future.</p><p>&quot;This isn&#x27;t just Intuit, this is the market as a whole,&quot; said Preston. &quot;Today we still have a lot of customers filling out forms and going through tables full of data. We&#x27;re investing a lot into leaning in and questioning the ways that we do it across our products today, where you&#x27;re basically just filling out, form after form, or table after table, because we see where the world is headed, which is really a different form of interacting with these products.&quot;</p><p>This creates a product design challenge: How do you serve users who are comfortable with traditional interfaces while gradually introducing conversational and agentic capabilities?</p><p>Intuit&#x27;s approach has been to embed AI agents directly into existing workflows. This means not forcing users to adopt entirely new interaction patterns. The payments agent appears alongside invoicing workflows; the accounting agent enhances the existing reconciliation process rather than replacing it. This incremental approach lets users experience AI benefits without abandoning familiar processes.</p><h2>What enterprise AI builders can learn from Intuit&#x27;s approach</h2><p>Intuit&#x27;s experience deploying AI in financial contexts surfaces several principles that apply broadly to enterprise AI initiatives. </p><p><b>Architecture matters for trust: </b>In domains where accuracy is critical, consider whether you need content generation or data query translation. Intuit&#x27;s decision to treat AI as an orchestration and natural language interface layer dramatically reduces hallucination risk and avoids using AI as a generative system.</p><p><b>Explainability must be designed in, not bolted on: </b>Showing users why the AI made a decision isn&#x27;t optional when trust is at stake. This requires deliberate UX design. It may constrain model choices.</p><p><b>User control preserves trust during accuracy improvements: </b>Intuit&#x27;s accounting agent improved categorization accuracy by 20 percentage points. Yet, maintaining user override capabilities was essential for adoption.</p><p><b>Transition gradually from familiar interfaces: </b>Don&#x27;t force users to abandon forms for conversations. Embed AI capabilities into existing workflows first. Let users experience benefits before asking them to change behavior.</p><p><b>Be honest about what&#x27;s reactive versus proactive: </b>Current AI agents primarily respond to prompts and automate defined tasks. True proactive intelligence that makes unprompted strategic recommendations remains an evolving capability. </p><p><b>Address workforce concerns with tooling, not just messaging: </b>If AI is meant to augment rather than replace workers, provide workers with AI tools. Show them how to leverage the technology.</p><p>For enterprises navigating AI adoption, Intuit&#x27;s journey offers a clear directive. The winning approach prioritizes trustworthiness over capability demonstrations. In domains where mistakes have real consequences, that means investing in accuracy, transparency and human oversight before pursuing conversational sophistication or autonomous action.</p><p>Simpson frames the challenge succinctly: &quot;We didn&#x27;t want it to be a bolted-on layer. We wanted customers to be in their natural workflow, and have agents doing work for customers, embedded in the workflow.&quot;</p>",
    "published": "Tue, 28 Oct 2025 12:30:00 GMT",
    "source_name": "venture_beat",
    "source_url": "https://venturebeat.com/feed/",
    "category": "tech_news",
    "weight": 0.8,
    "ai_relevance_score": 1.0,
    "timestamp": "2025-10-28T09:00:03.901419",
    "ready_for_mytribal": true,
    "parsed_date": null,
    "days_old": 999,
    "priority_score": 0.8
  },
  {
    "title": "PayPal’s Agentic Commerce Play Shows Why Flexibility, Not Standards, Will Define the Next E-Commerce Wave",
    "link": "https://venturebeat.com/ai/paypals-agentic-commerce-play-shows-why-flexibility-not-standards-will",
    "summary": "<p>While enterprises looking to sell goods and services online wait for the <a href=\"https://venturebeat.com/ai/google-vs-openai-vs-visa-competing-agent-protocols-threaten-the-future-of-ai\"><u>backbone of agentic commerce</u></a> to be hashed out, <a href=\"https://www.paypal.com/\"><u>PayPal</u></a> is hoping its new features will bridge the gap.</p><p>The payments company is launching a discoverability solution that allows enterprises to make its product available on any chat platform, regardless of the model or agent payment protocol. </p><p>PayPal, which is one of the participants for <a href=\"https://www.google.com/\"><u>Google</u></a>’s <a href=\"https://venturebeat.com/ai/googles-new-agent-payments-protocol-ap2-allows-ai-agents-to-complete\"><u>Agent Payments Protocol (AP2)</u></a>, found that it can leverage its relationship with merchants and enterprises to help pave the way for an easier transition into agentic commerce and offer the kind of flexibility they learned will benefit the ecosystem. </p><p>Michelle Gill, PayPal general manager for small business and financial services, told VentureBeat that AI-powered shopping will continue to grow, so enterprises and brands need to start laying the groundwork early. </p><p>“We think that merchants who&#x27;ve historically sold through web stores, particularly in the e-commerce space, are really going to need a way to get active on all of these large language models,” Gill said. “The challenge is that no one really knows how fast all of this is going to move. The issue that we’re trying to help merchants think through is how to do all of this as low-touch as possible while using the infrastructure you already have without doing a bazillion integrations.”</p><p>She added AI shopping would also bring about “a resurgence from consumers trying to ensure their investment is protected.”</p><p>PayPal partnered with website builder <a href=\"https://www.wix.com/\"><u>Wix</u></a>, <a href=\"https://www.cym.bio/\"><u>Cymbio</u></a>, Commerce and <a href=\"https://shopware.com/\"><u>Shopware</u></a> to bring products to chat platforms like <a href=\"https://www.perplexity.ai/\"><u>Perplexity</u></a>. \n</p><h2>Agent-powered shopping </h2><p>PayPal’s Agentic Commerce Services include two features. The first is Agent Ready, which would allow existing PayPal merchants to accept payments on AI platforms. The second is called Shop Sync, which will enable companies’ product data to be discoverable through different AI chat interfaces. It takes a company’s catalog information and plug its inventory and fulfillment data to chat platforms. </p><p>Gill said the data goes into a central repository where AI models can ingest the information. </p><p>Right now, companies can access shop sync with Agent Ready coming in 2026. </p><p>Gill said Agentic Commerce Services is a one-to-many solution, that would be helpful right now, as different LLMs scrape different data sources to surface information. </p><p>Other benefits include:</p><ul><li><p>Fast integration with current and future partners</p></li><li><p>More product discovery over the traditional search, browse and cart experiences</p></li><li><p>Preserved customer insights and relationships where the brand continues to have control over their records and communications with customers. </p></li></ul><p>Right now, the service is only available through Perplexity, but Gill said more platforms will be added soon. \n</p><h2>Fragmented AI platforms </h2><p>\nAgentic commerce is still very much in the early stages. AI agents are just beginning to get better at reading a browser. while platforms like ChatGPT, Gemini and Perplexity can now surface products and services based on user queries, people cannot technically buy things from chat yet.</p><p>There’s a race right now to create a standard to enable agents to transact on behalf of users and pay for items. Other than Google’s AP2, <a href=\"https://openai.com/\"><u>OpenAI</u></a> and <a href=\"https://stripe.com/\"><u>Stripe</u></a> have the <a href=\"https://venturebeat.com/ai/openai-debuts-new-chatgpt-buy-button-and-open-source-agentic-commerce\"><u>Agentic Commerce Protocol (ACP)</u></a> and <a href=\"https://usa.visa.com/\"><u>Visa</u></a> launched its <a href=\"https://venturebeat.com/ai/visa-just-launched-a-protocol-to-secure-the-ai-shopping-boom-heres-what-it\"><u>Trusted Agent Protocol</u></a>. </p><p>Other than enabling a trust layer for agents to transact, another issue enterprises face with agentic commerce is fragmentation. Different chat platforms use different models which also interpret information in slightly different ways. Gill said PayPal learned that when it comes to working with merchants, flexibility is important. </p><p>“How do you decide if you&#x27;re going to spend your time integrating with Google, Microsoft, ChatGPT or Perplexity? And each one of them right now has a different protocol, a different catalog, config, a different everything. That is a lot of time to make a bet as to like where you should spend your time,” Gill said. </p><p>\n\n\n\n\n</p>",
    "published": "Tue, 28 Oct 2025 04:00:00 GMT",
    "source_name": "venture_beat",
    "source_url": "https://venturebeat.com/feed/",
    "category": "tech_news",
    "weight": 0.8,
    "ai_relevance_score": 0.8,
    "timestamp": "2025-10-28T09:00:03.901635",
    "ready_for_mytribal": true,
    "parsed_date": null,
    "days_old": 999,
    "priority_score": 0.6400000000000001
  },
  {
    "title": "MiniMax-M2 is the new king of open source LLMs (especially for agentic tool calling)",
    "link": "https://venturebeat.com/ai/minimax-m2-is-the-new-king-of-open-source-llms-especially-for-agentic-tool",
    "summary": "<p>Watch out, DeepSeek and Qwen! There&#x27;s a new king of open source large language models (LLMs), especially when it comes to something enterprises are increasingly valuing: agentic tool use — that is, the ability to go off and use other software capabilities like web search or bespoke applications — without much human guidance. </p><p>That model is none other than <a href=\"https://x.com/MiniMax__AI/status/1982674798649160175\"><b>MiniMax-M2</b></a>, the latest LLM from the Chinese startup of the same name. And in a big win for enterprises globally, the model is available under a permissive, enterprise-friendly MIT License, meaning it is made available freely for developers to take, deploy, retrain, and use how they see fit — even for commercial purposes. It can be found on <a href=\"https://huggingface.co/MiniMaxAI/MiniMax-M2\">Hugging Face</a>, <a href=\"https://github.com/MiniMax-AI/MiniMax-M2\">GitHub</a> and <a href=\"https://www.modelscope.cn/models/MiniMax/MiniMax-M2\">ModelScope</a>, as well as through<a href=\"https://platform.minimax.io/docs/guides/text-generation\"> MiniMax&#x27;s API here.</a> It supports OpenAI and Anthropic API standards, as well, making it easy for customers of said proprietary AI startups to shift out their models to MiniMax&#x27;s API, if they want.</p><p>According to <a href=\"https://x.com/ArtificialAnlys/status/1982714153375854998\">independent evaluations by Artificial Analysis</a>, a third-party generative AI model benchmarking and research organization, M2 now ranks first among all open-weight systems worldwide on the Intelligence Index—a composite measure of reasoning, coding, and task-execution performance. </p><p>In agentic benchmarks that measure how well a model can plan, execute, and use external tools—skills that power coding assistants and autonomous agents—MiniMax’s own reported results, following the Artificial Analysis methodology, show τ²-Bench 77.2, BrowseComp 44.0, and FinSearchComp-global 65.5. </p><p>These scores place it at or near the level of top proprietary systems like GPT-5 (thinking) and Claude Sonnet 4.5, making <b>MiniMax-M2 the highest-performing open model yet released for real-world agentic and tool-calling tasks.</b></p><h3><b>What It Means For Enterprises and the AI Race</b></h3><p>Built around an efficient Mixture-of-Experts (MoE) architecture, MiniMax-M2 delivers high-end capability for agentic and developer workflows while remaining practical for enterprise deployment.</p><p>For technical decision-makers, the release marks an important turning point for open models in business settings. MiniMax-M2 combines frontier-level reasoning with a manageable activation footprint—just 10 billion active parameters out of 230 billion total. </p><p>This design enables enterprises to operate advanced reasoning and automation workloads on fewer GPUs, achieving near-state-of-the-art results without the infrastructure demands or licensing costs associated with proprietary frontier systems.</p><p>Artificial Analysis’ data show that MiniMax-M2’s strengths go beyond raw intelligence scores. The model leads or closely trails top proprietary systems such as GPT-5 (thinking) and Claude Sonnet 4.5 across benchmarks for end-to-end coding, reasoning, and agentic tool use. </p><p>Its performance in τ²-Bench, SWE-Bench, and BrowseComp indicates particular advantages for organizations that depend on AI systems capable of planning, executing, and verifying complex workflows—key functions for agentic and developer tools inside enterprise environments.</p><p>As LLM engineer Pierre-Carl Langlais aka <a href=\"https://x.com/Dorialexander/status/1982761110228127954\">Alexander Doria posted on X</a>: &quot;MiniMax [is] making a case for mastering the technology end-to-end to get actual agentic automation.&quot;</p><h3><b>Compact Design, Scalable Performance</b></h3><p>MiniMax-M2’s technical architecture is a sparse Mixture-of-Experts model with 230 billion total parameters and 10 billion active per inference. </p><p>This configuration significantly reduces latency and compute requirements while maintaining broad general intelligence. </p><p>The design allows for responsive agent loops—compile–run–test or browse–retrieve–cite cycles—that execute faster and more predictably than denser models.</p><p>For enterprise technology teams, this means easier scaling, lower cloud costs, and reduced deployment friction.<b> </b>According to Artificial Analysis, <b>the model can be served efficiently on as few as four NVIDIA H100 GPUs at FP8 precision</b>, a setup well within reach for mid-size organizations or departmental AI clusters.</p><h3><b>Benchmark Leadership Across Agentic and Coding Workflows</b></h3><p>MiniMax’s benchmark suite highlights strong real-world performance across developer and agent environments. The figure below, released with the model, compares MiniMax-M2 (in red) with several leading proprietary and open models, including GPT-5 (thinking), Claude Sonnet 4.5, Gemini 2.5 Pro, and DeepSeek-V3.2.</p><p>MiniMax-M2 achieves top or near-top performance in many categories:</p><ul><li><p>SWE-bench Verified: 69.4 — close to GPT-5’s 74.9</p></li><li><p>ArtifactsBench: 66.8 — above Claude Sonnet 4.5 and DeepSeek-V3.2</p></li><li><p>τ²-Bench: 77.2 — approaching GPT-5’s 80.1</p></li><li><p>GAIA (text only): 75.7 — surpassing DeepSeek-V3.2</p></li><li><p>BrowseComp: 44.0 — notably stronger than other open models</p></li><li><p>FinSearchComp-global: 65.5 — best among tested open-weight systems</p></li></ul><p>These results show MiniMax-M2’s capability in executing complex, tool-augmented tasks across multiple languages and environments—skills increasingly relevant for automated support, R&amp;D, and data analysis inside enterprises.</p><h3><b>Strong Showing in Artificial Analysis’ Intelligence Index</b></h3><p>The model’s overall intelligence profile is confirmed in the latest <b>Artificial Analysis Intelligence Index v3.0</b>, which aggregates performance across ten reasoning benchmarks including MMLU-Pro, GPQA Diamond, AIME 2025, IFBench, and τ²-Bench Telecom.</p><p><b>MiniMax-M2 scored 61 points</b>, ranking as the highest open-weight model globally and following closely behind GPT-5 (high) and Grok 4. </p><p>Artificial Analysis highlighted the model’s balance between technical accuracy, reasoning depth, and applied intelligence across domains. For enterprise users, this consistency indicates a reliable model foundation suitable for integration into software engineering, customer support, or knowledge automation systems.</p><h3><b>Designed for Developers and Agentic Systems</b></h3><p>MiniMax engineered M2 for end-to-end developer workflows, enabling multi-file code edits, automated testing, and regression repair directly within integrated development environments or CI/CD pipelines. </p><p>The model also excels in agentic planning—handling tasks that combine web search, command execution, and API calls while maintaining reasoning traceability.</p><p>These capabilities make MiniMax-M2 especially valuable for enterprises exploring autonomous developer agents, data analysis assistants, or AI-augmented operational tools. </p><p>Benchmarks such as Terminal-Bench and BrowseComp demonstrate the model’s ability to adapt to incomplete data and recover gracefully from intermediate errors, improving reliability in production settings.</p><h3><b>Interleaved Thinking and Structured Tool Use</b></h3><p>A distinctive aspect of MiniMax-M2 is its interleaved thinking format, which maintains visible reasoning traces between &lt;think&gt;...&lt;/think&gt; tags.</p><p>This enables the model to plan and verify steps across multiple exchanges, a critical feature for agentic reasoning. MiniMax advises retaining these segments when passing conversation history to preserve the model’s logic and continuity.</p><p>The company also provides a <a href=\"https://huggingface.co/MiniMaxAI/MiniMax-M2/blob/main/docs/tool_calling_guide.md\">Tool Calling Guide</a> on Hugging Face, detailing how developers can connect external tools and APIs via structured XML-style calls. </p><p>This functionality allows MiniMax-M2 to serve as the reasoning core for larger agent frameworks, executing dynamic tasks such as search, retrieval, and computation through external functions.</p><h3><b>Open Source Access and Enterprise Deployment Options</b></h3><p>Enterprises can access the model through the <a href=\"https://platform.minimax.io/docs/guides/platform-intro\">MiniMax Open Platform API </a>and <a href=\"https://agent.minimax.io/\">MiniMax Agent interface</a> (a web chat similar to ChatGPT), both currently free for a limited time.</p><p>MiniMax recommends SGLang and vLLM for efficient serving, each offering day-one support for the model’s unique interleaved reasoning and tool-calling structure. </p><p>Deployment guides and parameter configurations are available through MiniMax’s documentation.</p><h3><b>Cost Efficiency and Token Economics</b></h3><p>As Artificial Analysis noted, <a href=\"https://platform.minimax.io/docs/guides/pricing?key=68c79eb793ce7d2b318c5975\">MiniMax’s API pricing</a> is set at <b>$0.30 per million input tokens</b> and <b>$1.20 per million output tokens</b>, among the most competitive in the open-model ecosystem. </p><table><tbody><tr><td><p><b>Provider</b></p></td><td><p><b>Model (doc link)</b></p></td><td><p><b>Input $/1M</b></p></td><td><p><b>Output $/1M</b></p></td><td><p><b>Notes</b></p></td></tr><tr><td><p>MiniMax</p></td><td><p><a href=\"https://www.minimax.io/platform/document/pricing?key=68c79eb793ce7d2b318c5975\">MiniMax-M2</a></p></td><td><p><b>$0.30</b></p></td><td><p><b>$1.20</b></p></td><td><p>Listed under “Chat Completion v2” for M2. </p></td></tr><tr><td><p>OpenAI</p></td><td><p><a href=\"https://openai.com/api/pricing/\">GPT-5</a></p></td><td><p><b>$1.25</b></p></td><td><p><b>$10.00</b></p></td><td><p>Flagship model pricing on OpenAI’s API pricing page. </p></td></tr><tr><td><p>OpenAI</p></td><td><p><a href=\"https://openai.com/api/pricing/\">GPT-5 mini</a></p></td><td><p><b>$0.25</b></p></td><td><p><b>$2.00</b></p></td><td><p>Cheaper tier for well-defined tasks. </p></td></tr><tr><td><p>Anthropic</p></td><td><p><a href=\"https://docs.claude.com/en/docs/about-claude/pricing\">Claude Sonnet 4.5</a></p></td><td><p><b>$3.00</b></p></td><td><p><b>$15.00</b></p></td><td><p>Anthropic’s current per-MTok list; long-context (&gt;200K input) uses a premium tier. </p></td></tr><tr><td><p>Google</p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Gemini 2.5 Flash (Preview)</a></p></td><td><p><b>$0.30</b></p></td><td><p><b>$2.50</b></p></td><td><p>Prices include “thinking tokens”; page also lists cheaper Flash-Lite and 2.0 tiers. </p></td></tr><tr><td><p>xAI</p></td><td><p><a href=\"https://x.ai/api\">Grok-4 Fast (reasoning)</a></p></td><td><p><b>$0.20</b></p></td><td><p><b>$0.50</b></p></td><td><p>“Fast” tier; xAI also lists Grok-4 at $3 / $15. </p></td></tr><tr><td><p>DeepSeek</p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek-V3.2 (chat)</a></p></td><td><p><b>$0.28</b></p></td><td><p><b>$0.42</b></p></td><td><p>Cache-hit input is $0.028; table shows per-model details. </p></td></tr><tr><td><p>Qwen (Alibaba)</p></td><td><p><a href=\"https://www.alibabacloud.com/help/en/model-studio/models\">qwen-flash (Model Studio)</a></p></td><td><p><b>from $0.022</b></p></td><td><p><b>from $0.216</b></p></td><td><p>Tiered by input size (≤128K, ≤256K, ≤1M tokens); listed “Input price / Output price per 1M”. </p></td></tr><tr><td><p>Cohere</p></td><td><p><a href=\"https://cohere.com/pricing\">Command R+ (Aug 2024)</a></p></td><td><p><b>$2.50</b></p></td><td><p><b>$10.00</b></p></td><td><p>First-party pricing page also lists Command R ($0.50 / $1.50) and others. </p></td></tr></tbody></table><p><b>Notes &amp; caveats (for readers):</b></p><ul><li><p>Prices are USD per <b>million</b> tokens and can change; check linked pages for updates and region/endpoint nuances (e.g., Anthropic long-context &gt;200K input, Google Live API variants, cache discounts). </p></li><li><p>Vendors may bill extra for server-side tools (web search, code execution) or offer batch/context-cache discounts. </p></li></ul><p>While the model produces longer, more explicit reasoning traces, its sparse activation and optimized compute design help maintain a favorable cost-performance balance—an advantage for teams deploying interactive agents or high-volume automation systems.</p><h3><b>Background on MiniMax — an Emerging Chinese Powerhouse</b></h3><p>MiniMax has quickly become one of the most closely watched names in China’s fast-rising AI sector. </p><p>Backed by Alibaba and Tencent, the company moved from relative obscurity to international recognition within a year—first through breakthroughs in AI video generation, then through a series of open-weight large language models (LLMs) aimed squarely at developers and enterprises.</p><p>The company first captured <a href=\"https://venturebeat.com/ai/minimaxs-ai-video-tool-can-create-star-wars-battles-in-seconds-heres-why-that-matters\">global attention in late 2024 with its AI video generation tool</a>, “video-01,” which demonstrated the ability to create dynamic, cinematic scenes in seconds. VentureBeat described how the model’s launch sparked widespread interest after online creators began sharing lifelike, AI-generated footage—most memorably, a viral clip of a <i>Star Wars</i> lightsaber duel that drew millions of views in under two days. </p><p>CEO Yan Junjie emphasized that the system outperformed leading Western tools in generating human movement and expression, an area where video AIs often struggle. The product, later commercialized through MiniMax’s <i>Hailuo</i> platform, showcased the startup’s technical confidence and creative reach, helping to establish China as a serious contender in generative video technology.</p><p>By early 2025, MiniMax had turned its attention to long-context language modeling, unveiling the <a href=\"https://venturebeat.com/ai/minimax-unveils-its-own-open-source-llm-with-industry-leading-4m-token-context\">MiniMax-01 series, including MiniMax-Text-01 and MiniMax-VL-01</a>. These open-weight models introduced an unprecedented 4-million-token context window, doubling the reach of Google’s Gemini 1.5 Pro and dwarfing OpenAI’s GPT-4o by more than twentyfold. </p><p>The company continued its rapid cadence with the <a href=\"https://venturebeat.com/ai/minimax-m1-is-a-new-open-source-model-with-1-million-token-context-and-new-hyper-efficient-reinforcement-learning\">MiniMax-M1 release in June 2025</a>, a model focused on long-context reasoning and reinforcement learning efficiency. M1 extended context capacity to 1 million tokens and introduced a hybrid Mixture-of-Experts design trained using a custom reinforcement-learning algorithm known as CISPO. Remarkably, VentureBeat reported that MiniMax trained M1 at a total cost of about $534,700, roughly one-tenth of DeepSeek’s R1 and far below the multimillion-dollar budgets typical for frontier-scale models. </p><p>For enterprises and technical teams, MiniMax’s trajectory signals the arrival of a new generation of cost-efficient, open-weight models designed for real-world deployment. Its open licensing—ranging from Apache 2.0 to MIT—gives businesses freedom to customize, self-host, and fine-tune without vendor lock-in or compliance restrictions. </p><p>Features such as structured function calling, long-context retention, and high-efficiency attention architectures directly address the needs of engineering groups managing multi-step reasoning systems and data-intensive pipelines.</p><p>As MiniMax continues to expand its lineup, the company has emerged as a key global innovator in open-weight AI, combining ambitious research with pragmatic engineering. </p><h3><b>Open-Weight Leadership and Industry Context</b></h3><p>The release of MiniMax-M2 reinforces the growing leadership of Chinese AI research groups in open-weight model development. </p><p>Following earlier contributions from DeepSeek, Alibaba’s Qwen series, and Moonshot AI, MiniMax’s entry continues the trend toward open, efficient systems designed for real-world use. </p><p>Artificial Analysis observed that MiniMax-M2 exemplifies a broader shift in focus toward agentic capability and reinforcement-learning refinement, prioritizing controllable reasoning and real utility over raw model size.</p><p>For enterprises, this means access to a state-of-the-art open model that can be audited, fine-tuned, and deployed internally with full transparency. </p><p>By pairing strong benchmark performance with open licensing and efficient scaling, MiniMaxAI positions MiniMax-M2 as a practical foundation for intelligent systems that think, act, and assist with traceable logic—making it one of the most enterprise-ready open AI models available today.</p>",
    "published": "Mon, 27 Oct 2025 19:01:00 GMT",
    "source_name": "venture_beat",
    "source_url": "https://venturebeat.com/feed/",
    "category": "tech_news",
    "weight": 0.8,
    "ai_relevance_score": 1.0,
    "timestamp": "2025-10-28T09:00:03.902012",
    "ready_for_mytribal": true,
    "parsed_date": null,
    "days_old": 999,
    "priority_score": 0.8
  },
  {
    "title": "Anthropic rolls out Claude AI for finance, integrates with Excel to rival Microsoft Copilot",
    "link": "https://venturebeat.com/ai/anthropic-rolls-out-claude-ai-for-finance-integrates-with-excel-to-rival",
    "summary": "<p><a href=\"http://anthropic.com\"><u>Anthropic</u></a> is making its most aggressive push yet into the trillion-dollar financial services industry, unveiling a suite of tools that embed its <a href=\"http://claude.ai\"><u>Claude AI</u></a> assistant directly into <a href=\"https://www.microsoft.com/en-us/microsoft-365/excel\"><u>Microsoft Excel</u></a> and connect it to real-time market data from some of the world&#x27;s most influential financial information providers.</p><p>The San Francisco-based AI startup announced Monday it is releasing <a href=\"https://www.anthropic.com/news/advancing-claude-for-financial-services\"><u>Claude for Excel</u></a>, allowing financial analysts to interact with the AI system directly within their spreadsheets — the quintessential tool of modern finance. <!-- -->Beyond Excel, select Claude models are also being made available in <a href=\"https://www.microsoft.com/en/microsoft-copilot/microsoft-copilot-studio?market=af\"><u>Microsoft Copilot Studio</u></a> and <a href=\"https://www.microsoft.com/en-us/microsoft-365/blog/2025/03/25/introducing-researcher-and-analyst-in-microsoft-365-copilot/\"><u>Researcher agent</u></a>, expanding the integration across Microsoft&#x27;s enterprise AI ecosystem. <!-- -->The integration marks a significant escalation in Anthropic&#x27;s campaign to position itself as the AI platform of choice for banks, asset managers, and insurance companies, markets where precision and regulatory compliance matter far more than creative flair.</p><p>The expansion comes just three months after Anthropic launched its <a href=\"https://www.anthropic.com/news/claude-for-financial-services\"><u>Financial Analysis Solution</u></a> in July, and it signals the company&#x27;s determination to capture market share in an industry <a href=\"https://www.brookings.edu/articles/recommendations-for-responsible-use-of-ai-in-financial-services/\"><u>projected to spend $97 billion on AI by 2027</u></a>, up from $35 billion in 2023.</p><p>More importantly, it positions Anthropic to compete directly with <a href=\"https://microsoft.com/\"><u>Microsoft</u></a> — ironically, its partner in this Excel integration — which has its own <a href=\"https://www.microsoft.com/en-us/microsoft-365/excel/ai-for-excel\"><u>Copilot AI assistant</u></a> embedded across its <a href=\"https://www.microsoft.com/en-us/microsoft-365-copilot\"><u>Office suite</u></a>, and with <a href=\"https://openai.com/\"><u>OpenAI</u></a>, which counts <a href=\"https://www.nytimes.com/2025/09/11/technology/openai-microsoft-deal.html\"><u>Microsoft as its largest investor</u></a>.</p><h2><b>Why Excel has become the new battleground for AI in finance</b></h2><p>The decision to build directly into Excel is hardly accidental. Excel remains the lingua franca of finance, the digital workspace where analysts spend countless hours constructing financial models, running valuations, and stress-testing assumptions. By embedding Claude into this environment, Anthropic is meeting financial professionals exactly where they work rather than asking them to toggle between applications.</p><p>Claude for Excel allows users to work with the AI in a sidebar where it can read, analyze, modify, and create new Excel workbooks while providing full transparency about the actions it takes by tracking and explaining changes and letting users navigate directly to referenced cells.</p><p>This transparency feature addresses one of the most persistent anxieties around AI in finance: <a href=\"https://umdearborn.edu/news/ais-mysterious-black-box-problem-explained\"><u>the &quot;black box&quot; problem</u></a>. When billions of dollars ride on a financial model&#x27;s output, analysts need to understand not just the answer but how the AI arrived at it. By showing its work at the cell level, Anthropic is attempting to build the trust necessary for widespread adoption in an industry where careers and fortunes can turn on a misplaced decimal point.</p><p>The technical implementation is sophisticated. Claude can discuss how spreadsheets work, modify them while preserving formula dependencies — a notoriously complex task — debug cell formulas, populate templates with new data, or build entirely new spreadsheets from scratch. This isn&#x27;t merely a chatbot that answers questions about your data; it&#x27;s a collaborative tool that can actively manipulate the models that drive investment decisions worth trillions of dollars.</p><h2><b>How Anthropic is building data moats around its financial AI platform</b></h2><p>Perhaps more significant than the Excel integration is Anthropic&#x27;s expansion of its connector ecosystem, which now links Claude to live market data and proprietary research from financial information giants. The company added six major new data partnerships spanning the entire spectrum of financial information that professional investors rely upon.</p><p><a href=\"https://aiera.com/\"><u>Aiera</u></a> now provides Claude with real-time earnings call transcripts and summaries of investor events like shareholder meetings, presentations, and conferences. The Aiera connector also enables a data feed from <a href=\"https://www.thirdbridge.com/en-us\"><u>Third Bridge</u></a>, which gives Claude access to a library of insights interviews, company intelligence, and industry analysis from experts and former executives. <a href=\"https://www.chronograph.pe/\"><u>Chronograph</u></a> gives private equity investors operational and financial information for portfolio monitoring and conducting due diligence, including performance metrics, valuations, and fund-level data.</p><p><a href=\"https://www.egnyte.com/\"><u>Egnyte</u></a> enables Claude to securely search permitted data for internal data rooms, investment documents, and approved financial models while maintaining governed access controls. <a href=\"https://www.lseg.com/en\"><u>LSEG</u></a>, the London Stock Exchange Group, connects Claude to live market data including fixed income pricing, equities, foreign exchange rates, macroeconomic indicators, and analysts&#x27; estimates of other important financial metrics. <a href=\"https://www.moodys.com/\"><u>Moody&#x27;s</u></a> provides access to proprietary credit ratings, research, and company data covering ownership, financials, and news on more than 600 million public and private companies, supporting work and research in compliance, credit analysis, and business development. <a href=\"https://www.mtnewswires.com/\"><u>MT Newswires</u></a> provides Claude with access to the latest global multi-asset class news on financial markets and economies.</p><p>These partnerships amount to a land grab for the informational infrastructure that powers modern finance. Previously announced in July, Anthropic had <a href=\"https://www.anthropic.com/news/claude-for-financial-services\"><u>already secured integrations</u></a> with <a href=\"https://www.capitaliq.com/CIQDotNet/Login-okta.aspx\"><u>S&amp;P Capital IQ</u></a>, <a href=\"https://daloopa.com/\"><u>Daloopa</u></a>, <a href=\"https://www.morningstar.com/\"><u>Morningstar</u></a>, <a href=\"https://www.factset.com/\"><u>FactSet</u></a>, <a href=\"https://pitchbook.com/\"><u>PitchBook</u></a>, <a href=\"https://www.snowflake.com/en/\"><u>Snowflake</u></a>, and <a href=\"https://www.databricks.com/\"><u>Databricks</u></a>. Together, these connectors give Claude access to virtually every category of financial data an analyst might need: fundamental company data, market prices, credit assessments, private company intelligence, alternative data, and breaking news.</p><p>This matters because the quality of AI outputs depends entirely on the quality of inputs. Generic large language models trained on public internet data simply cannot compete with systems that have direct pipelines to Bloomberg-quality financial information. By securing these partnerships, Anthropic is building moats around its financial services offering that competitors will find difficult to replicate.</p><p>The strategic calculus here is clear: Anthropic is betting that domain-specific AI systems with privileged access to proprietary data will outcompete general-purpose AI assistants. It&#x27;s a direct challenge to the &quot;one AI to rule them all&quot; approach favored by some competitors.</p><h2><b>Pre-configured workflows target the daily grind of Wall Street analysts</b></h2><p>The third pillar of Anthropic&#x27;s announcement involves six new &quot;<a href=\"https://www.anthropic.com/news/skills\"><u>Agent Skills</u></a>&quot; — pre-configured workflows for common financial tasks. These skills are Anthropic&#x27;s attempt to productize the workflows of entry-level and mid-level financial analysts, professionals who spend their days building models, processing due diligence documents, and writing research reports. Anthropic has designed skills specifically to automate these time-consuming tasks.</p><p>The new skills include building discounted cash flow models complete with full free cash flow projections, weighted average cost of capital calculations, scenario toggles, and sensitivity tables. There&#x27;s comparable company analysis featuring valuation multiples and operating metrics that can be easily refreshed with updated data. Claude can now process data room documents into Excel spreadsheets populated with financial information, customer lists, and contract terms. It can create company teasers and profiles for pitch books and buyer lists, perform earnings analyses that use quarterly transcripts and financials to extract important metrics, guidance changes, and management commentary, and produce initiating coverage reports with industry analysis, company deep dives, and valuation frameworks.</p><p>It&#x27;s worth noting that Anthropic&#x27;s <a href=\"https://www.anthropic.com/news/claude-sonnet-4-5\"><u>Sonnet 4.5 model</u></a> now tops the <a href=\"https://www.vals.ai/benchmarks/finance_agent\"><u>Finance Agent benchmark</u></a> from Vals AI at 55.3% accuracy, a metric designed to test AI systems on tasks expected of entry-level financial analysts. A 55% accuracy rate might sound underwhelming, but it is state-of-the-art performance and highlights both the promise and limitations of AI in finance. The technology can clearly handle sophisticated analytical tasks, but it&#x27;s not yet reliable enough to operate autonomously without human oversight — a reality that may actually reassure both regulators and the analysts whose jobs might otherwise be at risk.</p><p>The <a href=\"https://www.anthropic.com/news/skills\"><u>Agent Skills</u></a> approach is particularly clever because it packages AI capabilities in terms that financial institutions already understand. Rather than selling generic &quot;AI assistance,&quot; Anthropic is offering solutions to specific, well-defined problems: &quot;You need a DCF model? We have a skill for that. You need to analyze earnings calls? We have a skill for that too.&quot;</p><h2><b>Trillion-dollar clients are already seeing massive productivity gains</b></h2><p>Anthropic&#x27;s financial services strategy appears to be gaining traction with exactly the kind of marquee clients that matter in enterprise sales. The company counts among its clients <a href=\"https://www.bridgewater.com/research-and-insights/artificial-intelligence\"><u>AIA Labs at Bridgewater</u></a>, <a href=\"https://www.commbank.com.au/\"><u>Commonwealth Bank of Australia</u></a>, <a href=\"https://www.aig.com/home\"><u>American International Group</u></a>, and <a href=\"https://www.nbim.no/\"><u>Norges Bank Investment Management</u></a> — Norway&#x27;s $1.6 trillion sovereign wealth fund, one of the world&#x27;s largest institutional investors.</p><p>NBIM CEO Nicolai Tangen reported achieving approximately 20% productivity gains, equivalent to 213,000 hours, with portfolio managers and risk departments now able to &quot;seamlessly query our Snowflake data warehouse and analyze earnings calls with unprecedented efficiency.&quot;</p><p>At AIG, CEO Peter Zaffino said the partnership has &quot;compressed the timeline to review business by more than 5x in our early rollouts while simultaneously improving our data accuracy from 75% to over 90%.&quot; If these numbers hold across broader deployments, the productivity implications for the financial services industry are staggering.</p><p>These aren&#x27;t pilot programs or proof-of-concept deployments; they&#x27;re production implementations at institutions managing trillions of dollars in assets and making underwriting decisions that affect millions of customers. Their public endorsements provide the social proof that typically drives enterprise adoption in conservative industries.</p><h2><b>Regulatory uncertainty creates both opportunity and risk for AI deployment</b></h2><p>Yet Anthropic&#x27;s financial services ambitions unfold against a backdrop of heightened regulatory scrutiny and shifting enforcement priorities. In 2023, the <a href=\"https://www.consumerfinance.gov/about-us/newsroom/cfpb-issues-guidance-on-credit-denials-by-lenders-using-artificial-intelligence/\"><u>Consumer Financial Protection Bureau</u></a> released guidance requiring lenders to &quot;use specific and accurate reasons when taking adverse actions against consumers&quot; involving AI, and issued additional guidance requiring regulated entities to &quot;evaluate their underwriting models for bias&quot; and &quot;evaluate automated collateral-valuation and appraisal processes in ways that minimize bias.&quot;</p><p>However, according to a <a href=\"https://www.brookings.edu/articles/recommendations-for-responsible-use-of-ai-in-financial-services/\"><u>Brookings Institution analysis</u></a>, these measures have since been revoked with work stopped or eliminated at the current downsized CFPB under the current administration, creating regulatory uncertainty. The pendulum has swung from the Biden administration&#x27;s cautious approach, exemplified by an <a href=\"https://bidenwhitehouse.archives.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/\"><u>executive order on safe AI development</u></a>, toward the Trump administration&#x27;s &quot;<a href=\"https://www.whitehouse.gov/wp-content/uploads/2025/07/Americas-AI-Action-Plan.pdf\"><u>America&#x27;s AI Action Plan</u></a>,&quot; which seeks to &quot;cement U.S. dominance in artificial intelligence&quot; through deregulation.</p><p>This regulatory flux creates both opportunities and risks. Financial institutions eager to deploy AI now face less prescriptive federal oversight, potentially accelerating adoption. But the absence of clear guardrails also exposes them to potential liability if AI systems produce discriminatory outcomes, particularly in lending and underwriting.</p><p>The Massachusetts Attorney General recently reached a <a href=\"https://www.mass.gov/news/ag-campbell-announces-25-million-settlement-with-student-loan-lender-for-unlawful-practices-through-ai-use-other-consumer-protection-violations\"><u>$2.5 million settlement</u></a> with student loan company Earnest Operations, alleging that its use of AI models resulted in &quot;disparate impact in approval rates and loan terms, specifically disadvantaging Black and Hispanic applicants.&quot; Such cases will likely multiply as AI deployment grows, creating a patchwork of state-level enforcement even as federal oversight recedes.</p><p>Anthropic appears acutely aware of these risks. In an interview with <a href=\"https://www.bankingdive.com/news/anthropic-rolls-out-financial-ai-tools-target-large-clients-claude/753249/\"><u>Banking Dive</u></a>, Jonathan Pelosi, Anthropic&#x27;s global head of industry for financial services, emphasized that Claude requires a &quot;human in the loop.&quot; The platform, he said, is not intended for autonomous financial decision-making or to provide stock recommendations that users follow blindly. During client onboarding, Pelosi told the publication, Anthropic focuses on training and understanding model limitations, putting guardrails in place so people treat Claude as a helpful technology rather than a replacement for human judgment.</p><h2><b>Competition heats up as every major tech company targets finance AI</b></h2><p>Anthropic&#x27;s financial services push comes as AI competition intensifies across the enterprise. <a href=\"https://openai.com/\"><u>OpenAI</u></a>, <a href=\"https://www.microsoft.com/en-us/\"><u>Microsoft</u></a>, <a href=\"https://www.google.com/?zx=1761550720312&amp;no_sw_cr=1\"><u>Google</u></a>, and numerous startups are all vying for position in what may become one of AI&#x27;s most lucrative verticals. <a href=\"https://www.cnbc.com/2025/01/21/goldman-sachs-launches-ai-assistant.html\"><u>Goldman Sachs</u></a> introduced a generative AI assistant to its bankers, traders, and asset managers in January, signaling that major banks may build their own capabilities rather than rely exclusively on third-party providers.</p><p>The emergence of domain-specific AI models like <a href=\"https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/\"><u>BloombergGPT</u></a> — trained specifically on financial data — suggests the market may fragment between generalized AI assistants and specialized tools. Anthropic&#x27;s strategy appears to stake out a middle ground: general-purpose models, since Claude was not trained exclusively on financial data, enhanced with financial-specific tooling, data access, and workflows.</p><p>The company&#x27;s partnership strategy with implementation consultancies including <a href=\"https://www.deloitte.com/us/en.html\"><u>Deloitte</u></a>, <a href=\"https://kpmg.com/xx/en.html\"><u>KPMG</u></a>, <a href=\"https://www.pwc.com/us/en/leadingedge.html?WT.mc_id=CT3-PL300-DM1-TR1-BR_XB_-OTHERFW_-Brand_Umbrella_Google&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=22496735884&amp;gbraid=0AAAAABTtm-J1jFUwZ3oXf5hR5VenXYQfh&amp;gclid=Cj0KCQjwsPzHBhDCARIsALlWNG0UNXvoWOQLTYylq3foXvjRNwHOD6SRzXaav5gXQG2APeHyRz5Us34aAn0lEALw_wcB\"><u>PwC</u></a>, <a href=\"https://www.slalom.com/us/en\"><u>Slalom</u></a>, <a href=\"https://www.tribe.ai/\"><u>TribeAI</u></a>, and <a href=\"https://www.turing.com/\"><u>Turing</u></a> is equally critical. These firms serve as force multipliers, embedding Anthropic&#x27;s technology into their own service offerings and providing the change management expertise that financial institutions need to successfully adopt AI at scale.</p><h2><b>CFOs worry about AI hallucinations and cascading errors</b></h2><p>The broader question is whether AI tools like Claude will genuinely transform financial services productivity or merely shift work around. The PYMNTS Intelligence report &quot;<a href=\"https://www.pymnts.com/study_posts/the-agentic-trust-gap-enterprise-cfos-push-pause-on-agentic-ai/\"><u>The Agentic Trust Gap</u></a>&quot; found that chief financial officers remain hesitant about AI agents, with &quot;nagging concern&quot; about hallucinations where &quot;an AI agent can go off script and expose firms to cascading payment errors and other inaccuracies.&quot;</p><p>&quot;For finance leaders, the message is stark: Harness AI&#x27;s momentum now, but build the guardrails before the next quarterly call—or risk owning the fallout,&quot; the report warned.</p><p>A <a href=\"https://kpmg.com/kpmg-us/content/dam/kpmg/boardleadership/pdf/2025/2025-survey-boardroom-lens-generative-ai.pdf\"><u>2025 KPMG report</u></a> found that 70% of board members have developed responsible use policies for employees, with other popular initiatives including implementing a recognized AI risk and governance framework, developing ethical guidelines and training programs for AI developers, and conducting regular AI use audits.</p><p>The financial services industry faces a delicate balancing act: move too slowly and risk competitive disadvantage as rivals achieve productivity gains; move too quickly and risk operational failures, regulatory penalties, or reputational damage. Speaking at the <a href=\"https://evidentinsights.com/events/evident-ai-symposium-new-york-2025/\"><u>Evident AI Symposium</u></a> in New York last week, Ian Glasner, HSBC&#x27;s group head of emerging technology, innovation and ventures, struck an optimistic tone about the sector&#x27;s readiness for AI adoption. &quot;As an industry, we are very well prepared to manage risk,&quot; he said, according to <a href=\"https://www.ciodive.com/news/agentic-ai-governance-risk-mitigation-financial-services-banks/803667/\"><u>CIO Dive</u></a>. &quot;Let&#x27;s not overcomplicate this. We just need to be focused on the business use case and the value associated.&quot;</p><p>Anthropic&#x27;s latest moves suggest the company sees financial services as a beachhead market where AI&#x27;s value proposition is clear, customers have deep pockets, and the technical requirements play to Claude&#x27;s strengths in reasoning and accuracy. By building Excel integration, securing data partnerships, and pre-packaging common workflows, Anthropic is reducing the friction that typically slows enterprise AI adoption.</p><p>The<a href=\"https://www.anthropic.com/news/anthropic-raises-series-e-at-usd61-5b-post-money-valuation\"><u> $61.5 billion valuation</u></a> the company commanded in its March fundraising round — up from roughly $16 billion a year earlier — suggests investors believe this strategy will work. But the real test will come as these tools move from pilot programs to production deployments across thousands of analysts and billions of dollars in transactions.</p><p>Financial services may prove to be AI&#x27;s most demanding proving ground: an industry where mistakes are costly, regulation is stringent, and trust is everything. If Claude can successfully navigate the spreadsheet cells and data feeds of Wall Street without hallucinating a decimal point in the wrong direction, Anthropic will have accomplished something far more valuable than winning another benchmark test. It will have proven that AI can be trusted with the money.</p><p>\n</p>",
    "published": "Mon, 27 Oct 2025 16:00:00 GMT",
    "source_name": "venture_beat",
    "source_url": "https://venturebeat.com/feed/",
    "category": "tech_news",
    "weight": 0.8,
    "ai_relevance_score": 1.0,
    "timestamp": "2025-10-28T09:00:03.902518",
    "ready_for_mytribal": true,
    "parsed_date": null,
    "days_old": 999,
    "priority_score": 0.8
  },
  {
    "title": "How AI-powered cameras are redefining business intelligence",
    "link": "https://venturebeat.com/data-infrastructure/how-ai-powered-cameras-are-redefining-business-intelligence",
    "summary": "<p><i>Presented by Axis Communications </i></p><hr /><p>Many businesses are equipped with a network of intelligent eyes that span operations. These IP cameras and intelligent edge devices were once solely focused on ensuring the safety of employees, customers, and inventory. These technologies have long proved to be essential tools for businesses, and while this sentiment still rings true, they’re now emerging as powerful resources.</p><p>These cameras and edge devices have rapidly evolved into real-time data producers. IP cameras can now see and understand, and the accompanying artificial intelligence helps companies and decision-makers generate business intelligence, improve operational efficiency, and gain a competitive advantage.</p><p>By treating cameras as vision sensors and sources of operational insight, businesses can transform everyday visibility into measurable business value.</p><h3><b>Intelligence on the edge</b></h3><p>Network cameras have come a long way since Axis Communications first introduced this technology in 1996. Over time, innovations like the ARTPEC chip, the first chip purpose-built for IP video, helped enhance image quality, analytics, and encoding performance.</p><p>Today, these intelligent devices are powering a new generation of business intelligence and operational efficiency solutions via embedded AI. Actionable insights are now fed directly into intelligence platforms, ERP systems, and real-time dashboards, and the results are significant and far-reaching.</p><p>In manufacturing, intelligent cameras are detecting defects on the production line early, before an entire production run is compromised. In retail, these cameras can run software that maps customer journeys and optimizes product placement. In healthcare, these solutions help facilities enhance patient care while improving operational efficiency and reducing costs.</p><p>The combination of video and artificial intelligence has significantly expanded what cameras can do —  transforming them into vital tools for improving business performance.</p><h3><b>Proof in practice</b></h3><p>Companies are creatively taking advantage of edge devices like AI-enabled cameras to improve business intelligence and operational efficiencies. </p><p><a href=\"https://www.axis.com/customer-story/axis-industrial-vehicle-production\"><b>BMW</b></a> has relied on intelligent IP cameras to optimize efficiency and product quality, with AI-driven video systems catching defects that are often invisible to the human eye. Or take <a href=\"https://newsroom.axis.com/blog/retail-insights\"><b>Google Cloud’s shelf-checking AI technology</b>,</a> an innovative software that allows retailers to make instant restocking decisions using real-time data. </p><p>These technologies appeal to far more than retailers and vendors. The <a href=\"https://newsroom.axis.com/en-us/press-release/ac-camargo\"><b>A.C. Camargo Cancer Center</b></a> in Brazil uses network cameras to reduce theft, assure visitor and employee safety, and optimize patient flow. By relying on newfound business intelligence, the facility has saved more than $2 million in operational costs through two years, with those savings being reinvested directly into patient care. </p><p>Urban projects can also benefit from edge devices and artificial intelligence. For example, <a href=\"https://newsroom.axis.com/en-us/press-release/vanderbilt-university\"><b>Vanderbilt University</b></a> turned to video analytics to study traffic flow, relying on AI to uncover the causes of phantom congestion and enabling smarter traffic management. These studies will have additional impact on the local environment and public, as the learnings can be used to optimize safety, air quality, and fuel efficiency. </p><p>Each case illustrates the same point: AI-powered cameras can fuel a tangible return on investment and crucial business intelligence, regardless of the industry.</p><h3><b>Preparing for the next phase</b></h3><p>The role of AI in video intelligence is still expanding, with several emerging trends driving greater advancements and impact in the years ahead:</p><ul><li><p><b>Predictive operations: </b>cameras that are capable of forecasting needs or risks through predictive analytics</p></li><li><p><b>Versatile analytics: </b>systems that incorporate audio, thermal, and environmental sensors for more comprehensive and accurate insights</p></li><li><p><b>Technological collaboration: </b>cameras that integrate with other intelligent edge devices to autonomously manage tasks</p></li><li><p><b>Sustainability initiatives: </b>intelligent technologies that reduce energy use and support resource efficiency</p></li></ul><p>Axis Communications helps advance these possibilities with open-source, scalable systems engineered to address both today’s challenges and tomorrow’s opportunities. By staying ahead of this ever-changing environment, Axis helps ensure that organizations continue to benefit from actionable business intelligence while maintaining the highest standards of security and safety.</p><p>Cameras have evolved beyond simple surveillance tools. They are strategic assets that inform operations, foster innovation, and enable future readiness. Business leaders who cling to traditional views of IP cameras and edge devices risk missing opportunities for efficiency and innovation. Those who embrace an AI-driven approach can expect not only stronger security but also better business outcomes.</p><p>Ultimately, the value of IP cameras and edge devices lies not in categories but in capabilities. In an era of rapidly evolving artificial intelligence, these unique technologies will become indispensable to overall business success.</p><hr /><p><i><b>About Axis Communications</b></i></p><p>Axis enables a smarter and safer world by improving security, safety, operational efficiency, and business intelligence. As a network technology company and industry leader, Axis offers video surveillance, access control, intercoms, and audio solutions. These are enhanced by intelligent analytics applications and supported by high-quality training.</p><p>Axis has around 5,000 dedicated employees in over 50 countries and collaborates with technology and system integration partners worldwide to deliver customer solutions. Axis was founded in 1984, and the headquarters are in Lund, Sweden.</p><hr /><p><i>Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact </i><a href=\"mailto:sales@venturebeat.com\"><i><u>sales@venturebeat.com</u></i></a><i>.</i></p>",
    "published": "Mon, 27 Oct 2025 04:00:00 GMT",
    "source_name": "venture_beat",
    "source_url": "https://venturebeat.com/feed/",
    "category": "tech_news",
    "weight": 0.8,
    "ai_relevance_score": 1.0,
    "timestamp": "2025-10-28T09:00:03.902741",
    "ready_for_mytribal": true,
    "parsed_date": null,
    "days_old": 999,
    "priority_score": 0.8
  },
  {
    "title": "Thinking Machines challenges OpenAI's AI scaling strategy: 'First superintelligence will be a superhuman learner'",
    "link": "https://venturebeat.com/ai/thinking-machines-challenges-openais-ai-scaling-strategy-first",
    "summary": "<p>While the world&#x27;s leading artificial intelligence companies race to build ever-larger models, betting billions that scale alone will unlock artificial general intelligence, a researcher at one of the industry&#x27;s most secretive and valuable startups delivered a pointed challenge to that orthodoxy this week: The path forward isn&#x27;t about training bigger — it&#x27;s about learning better.</p><p>&quot;I believe that the first superintelligence will be a superhuman learner,&quot; <a href=\"https://rmrafailov.github.io/\"><u>Rafael Rafailov</u></a>, a reinforcement learning researcher at <a href=\"https://thinkingmachines.ai/\"><u>Thinking Machines Lab</u></a>, told an audience at TED AI San Francisco on Tuesday. &quot;It will be able to very efficiently figure out and adapt, propose its own theories, propose experiments, use the environment to verify that, get information, and iterate that process.&quot;</p><p>This breaks sharply with the approach pursued by <a href=\"https://openai.com/\"><u>OpenAI</u></a>, <a href=\"https://anthropic.com/\"><u>Anthropic</u></a>, <a href=\"https://deepmind.google/\"><u>Google DeepMind</u></a>, and other leading laboratories, which have bet billions on scaling up model size, data, and compute to achieve increasingly sophisticated reasoning capabilities. Rafailov argues these companies have the strategy backwards: what&#x27;s missing from today&#x27;s most advanced AI systems isn&#x27;t more scale — it&#x27;s the ability to actually learn from experience.</p><p>&quot;Learning is something an intelligent being does,&quot; Rafailov said, citing a quote he described as recently compelling. &quot;Training is something that&#x27;s being done to it.&quot;</p><p>The distinction cuts to the core of how AI systems improve — and whether the industry&#x27;s current trajectory can deliver on its most ambitious promises. Rafailov&#x27;s comments offer a rare window into the thinking at <a href=\"https://thinkingmachines.ai/\"><u>Thinking Machines Lab</u></a>, the startup co-founded in February by former OpenAI chief technology officer <a href=\"https://x.com/miramurati?lang=en\"><u>Mira Murati</u></a> that raised a record-breaking <a href=\"https://www.reuters.com/technology/mira-muratis-ai-startup-thinking-machines-raises-2-billion-a16z-led-round-2025-07-15/\"><u>$2 billion in seed funding</u></a> at a $12 billion valuation.</p><h2><b>Why today&#x27;s AI coding assistants forget everything they learned yesterday</b></h2><p>To illustrate the problem with current AI systems, Rafailov offered a scenario familiar to anyone who has worked with today&#x27;s most advanced coding assistants.</p><p>&quot;If you use a coding agent, ask it to do something really difficult — to implement a feature, go read your code, try to understand your code, reason about your code, implement something, iterate — it might be successful,&quot; he explained. &quot;And then come back the next day and ask it to implement the next feature, and it will do the same thing.&quot;</p><p>The issue, he argued, is that these systems don&#x27;t internalize what they learn. &quot;In a sense, for the models we have today, every day is their first day of the job,&quot; Rafailov said. &quot;But an intelligent being should be able to internalize information. It should be able to adapt. It should be able to modify its behavior so every day it becomes better, every day it knows more, every day it works faster — the way a human you hire gets better at the job.&quot;</p><h2><b>The duct tape problem: How current training methods teach AI to take shortcuts instead of solving problems</b></h2><p>Rafailov pointed to a specific behavior in coding agents that reveals the deeper problem: their tendency to wrap uncertain code in <a href=\"https://www.w3schools.com/python/python_try_except.asp\"><u>try/except blocks</u></a> — a programming construct that catches errors and allows a program to continue running.</p><p>&quot;If you use coding agents, you might have observed a very annoying tendency of them to use try/except pass,&quot; he said. &quot;And in general, that is basically just like duct tape to save the entire program from a single error.&quot;</p><p>Why do agents do this? &quot;They do this because they understand that part of the code might not be right,&quot; Rafailov explained. &quot;They understand there might be something wrong, that it might be risky. But under the limited constraint—they have a limited amount of time solving the problem, limited amount of interaction—they must only focus on their objective, which is implement this feature and solve this bug.&quot;</p><p>The result: &quot;They&#x27;re kicking the can down the road.&quot;</p><p>This behavior stems from training systems that optimize for immediate task completion. &quot;The only thing that matters to our current generation is solving the task,&quot; he said. &quot;And anything that&#x27;s general, anything that&#x27;s not related to just that one objective, is a waste of computation.&quot;</p><h2><b>Why throwing more compute at AI won&#x27;t create superintelligence, according to Thinking Machines researcher</b></h2><p>Rafailov&#x27;s most direct challenge to the industry came in his assertion that continued scaling won&#x27;t be sufficient to reach AGI.</p><p>&quot;I don&#x27;t believe we&#x27;re hitting any sort of saturation points,&quot; he clarified. &quot;I think we&#x27;re just at the beginning of the next paradigm—the scale of reinforcement learning, in which we move from teaching our models how to think, how to explore thinking space, into endowing them with the capability of general agents.&quot;</p><p>In other words, current approaches will produce increasingly capable systems that can interact with the world, browse the web, write code. &quot;I believe a year or two from now, we&#x27;ll look at our coding agents today, research agents or browsing agents, the way we look at summarization models or translation models from several years ago,&quot; he said.</p><p>But general agency, he argued, is not the same as general intelligence. &quot;The much more interesting question is: Is that going to be AGI? And are we done — do we just need one more round of scaling, one more round of environments, one more round of RL, one more round of compute, and we&#x27;re kind of done?&quot;</p><p>His answer was unequivocal: &quot;I don&#x27;t believe this is the case. I believe that under our current paradigms, under any scale, we are not enough to deal with artificial general intelligence and artificial superintelligence. And I believe that under our current paradigms, our current models will lack one core capability, and that is learning.&quot;</p><h2><b>Teaching AI like students, not calculators: The textbook approach to machine learning</b></h2><p>To explain the alternative approach, Rafailov turned to an analogy from mathematics education.</p><p>&quot;Think about how we train our current generation of reasoning models,&quot; he said. &quot;We take a particular math problem, make it very hard, and try to solve it, rewarding the model for solving it. And that&#x27;s it. Once that experience is done, the model submits a solution. Anything it discovers—any abstractions it learned, any theorems—we discard, and then we ask it to solve a new problem, and it has to come up with the same abstractions all over again.&quot;</p><p>That approach misunderstands how knowledge accumulates. &quot;This is not how science or mathematics works,&quot; he said. &quot;We build abstractions not necessarily because they solve our current problems, but because they&#x27;re important. For example, we developed the field of topology to extend Euclidean geometry — not to solve a particular problem that Euclidean geometry couldn&#x27;t handle, but because mathematicians and physicists understood these concepts were fundamentally important.&quot;</p><p>The solution: &quot;Instead of giving our models a single problem, we might give them a textbook. Imagine a very advanced graduate-level textbook, and we ask our models to work through the first chapter, then the first exercise, the second exercise, the third, the fourth, then move to the second chapter, and so on—the way a real student might teach themselves a topic.&quot;</p><p>The objective would fundamentally change: &quot;Instead of rewarding their success — how many problems they solved — we need to reward their progress, their ability to learn, and their ability to improve.&quot;</p><p>This approach, known as &quot;<a href=\"https://en.wikipedia.org/wiki/Meta-learning_(computer_science)\"><u>meta-learning</u></a>&quot; or &quot;<a href=\"https://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/\"><u>learning to learn</u></a>,&quot; has precedents in earlier AI systems. &quot;Just like the ideas of scaling test-time compute and search and test-time exploration played out in the domain of games first&quot; — in systems like <a href=\"https://deepmind.google/research/projects/alphago/\"><u>DeepMind&#x27;s AlphaGo</u></a> — &quot;the same is true for meta learning. We know that these ideas do work at a small scale, but we need to adapt them to the scale and the capability of foundation models.&quot;</p><h2><b>The missing ingredients for AI that truly learns aren&#x27;t new architectures—they&#x27;re better data and smarter objectives</b></h2><p>When Rafailov addressed why current models lack this learning capability, he offered a surprisingly straightforward answer.</p><p>&quot;Unfortunately, I think the answer is quite prosaic,&quot; he said. &quot;I think we just don&#x27;t have the right data, and we don&#x27;t have the right objectives. I fundamentally believe a lot of the core architectural engineering design is in place.&quot;</p><p>Rather than arguing for entirely new model architectures, Rafailov suggested the path forward lies in redesigning the <a href=\"https://julius.ai/glossary/data-distribution\"><u>data distributions</u></a> and <a href=\"https://arxiv.org/html/2408.10215v1\"><u>reward structures</u></a> used to train models.</p><p>&quot;Learning, in of itself, is an algorithm,&quot; he explained. &quot;It has inputs — the current state of the model. It has data and compute. You process it through some sort of structure, choose your favorite optimization algorithm, and you produce, hopefully, a stronger model.&quot;</p><p>The question: &quot;If reasoning models are able to learn general reasoning algorithms, general search algorithms, and agent models are able to learn general agency, can the next generation of AI learn a learning algorithm itself?&quot;</p><p>His answer: &quot;I strongly believe that the answer to this question is yes.&quot;</p><p>The technical approach would involve creating training environments where &quot;learning, adaptation, exploration, and self-improvement, as well as generalization, are necessary for success.&quot;</p><p>&quot;I believe that under enough computational resources and with broad enough coverage, general purpose learning algorithms can emerge from large scale training,&quot; Rafailov said. &quot;The way we train our models to reason in general over just math and code, and potentially act in general domains, we might be able to teach them how to learn efficiently across many different applications.&quot;</p><h2><b>Forget god-like reasoners: The first superintelligence will be a master student</b></h2><p>This vision leads to a fundamentally different conception of what artificial superintelligence might look like.</p><p>&quot;I believe that if this is possible, that&#x27;s the final missing piece to achieve truly efficient general intelligence,&quot; Rafailov said. &quot;Now imagine such an intelligence with the core objective of exploring, learning, acquiring information, self-improving, equipped with general agency capability—the ability to understand and explore the external world, the ability to use computers, ability to do research, ability to manage and control robots.&quot;</p><p>Such a system would constitute artificial superintelligence. But not the kind often imagined in science fiction.</p><p>&quot;I believe that intelligence is not going to be a single god model that&#x27;s a god-level reasoner or a god-level mathematical problem solver,&quot; Rafailov said. &quot;I believe that the first superintelligence will be a superhuman learner, and it will be able to very efficiently figure out and adapt, propose its own theories, propose experiments, use the environment to verify that, get information, and iterate that process.&quot;</p><p>This vision stands in contrast to OpenAI&#x27;s emphasis on building <a href=\"https://www.nytimes.com/2025/04/16/technology/openai-reasoning-models-o3-o4-mini.html\"><u>increasingly powerful reasoning systems</u></a>, or Anthropic&#x27;s focus on &quot;<a href=\"https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback\"><u>constitutional AI</u></a>.&quot; Instead, Thinking Machines Lab appears to be betting that the path to superintelligence runs through systems that can continuously improve themselves through interaction with their environment.</p><h2><b>The $12 billion bet on learning over scaling faces formidable challenges</b></h2><p>Rafailov&#x27;s appearance comes at a complex moment for <a href=\"https://thinkingmachines.ai/\"><u>Thinking Machines Lab</u></a>. The company has assembled an impressive team of approximately 30 researchers from <a href=\"https://openai.com/\"><u>OpenAI</u></a>, <a href=\"https://www.google.com/\"><u>Google</u></a>, <a href=\"https://www.meta.com/\"><u>Meta</u></a>, and other leading labs. But it suffered a setback in early October when Andrew Tulloch, a co-founder and machine learning expert, departed to return to Meta after the company launched what The Wall Street Journal called a &quot;<a href=\"https://www.wsj.com/tech/ai/meta-zuckerberg-ai-recruiting-fail-e6107555?gaa_at=eafs&amp;gaa_n=AWEtsqc_-cB9wl3ZPgtqZ__eBCeYWyT9I0pNgGVMy4Y898FrhtFnq3tSx4HFZHBFSzU%3D&amp;gaa_ts=68fbf024&amp;gaa_sig=rxhAZjpOFkPvuz6hDIoRcezY0lcbtglzljasLalVhtZWykfDMjIa_V4IS4mobhEUfRRXwH_qaEixofFop4Ec3g%3D%3D\"><u>full-scale raid</u></a>&quot; on the startup, approaching more than a dozen employees with compensation packages ranging from $200 million to $1.5 billion over multiple years.</p><p>Despite these pressures, Rafailov&#x27;s comments suggest the company remains committed to its differentiated technical approach. The company launched its first product, <a href=\"https://venturebeat.com/ai/thinking-machines-first-official-product-is-here-meet-tinker-an-api-for\"><u>Tinker</u></a>, an API for fine-tuning open-source language models, in October. But Rafailov&#x27;s talk suggests Tinker is just the foundation for a much more ambitious research agenda focused on meta-learning and self-improving systems.</p><p>&quot;This is not easy. This is going to be very difficult,&quot; Rafailov acknowledged. &quot;We&#x27;ll need a lot of breakthroughs in memory and engineering and data and optimization, but I think it&#x27;s fundamentally possible.&quot;</p><p>He concluded with a play on words: &quot;The world is not enough, but we need the right experiences, and we need the right type of rewards for learning.&quot;</p><p>The question for <a href=\"https://thinkingmachines.ai/\"><u>Thinking Machines Lab</u></a> — and the broader AI industry — is whether this vision can be realized, and on what timeline. Rafailov notably did not offer specific predictions about when such systems might emerge.</p><p>In an industry where executives routinely make bold predictions about AGI arriving within years or even months, that restraint is notable. It suggests either unusual scientific humility — or an acknowledgment that Thinking Machines Lab is pursuing a much longer, harder path than its competitors.</p><p>For now, the most revealing detail may be what Rafailov didn&#x27;t say during his TED AI presentation. No timeline for when superhuman learners might emerge. No prediction about when the technical breakthroughs would arrive. Just a conviction that the capability was &quot;fundamentally possible&quot; — and that without it, all the scaling in the world won&#x27;t be enough.</p><p>\n</p>",
    "published": "Fri, 24 Oct 2025 09:30:00 GMT",
    "source_name": "venture_beat",
    "source_url": "https://venturebeat.com/feed/",
    "category": "tech_news",
    "weight": 0.8,
    "ai_relevance_score": 1.0,
    "timestamp": "2025-10-28T09:00:03.903592",
    "ready_for_mytribal": true,
    "parsed_date": null,
    "days_old": 999,
    "priority_score": 0.8
  },
  {
    "title": "OpenAI says over a million people talk to ChatGPT about suicide weekly",
    "link": "https://www.reddit.com/r/artificial/comments/1oi5ove/openai_says_over_a_million_people_talk_to_chatgpt/",
    "summary": "<table> <tr><td> <a href=\"https://www.reddit.com/r/artificial/comments/1oi5ove/openai_says_over_a_million_people_talk_to_chatgpt/\"> <img alt=\"OpenAI says over a million people talk to ChatGPT about suicide weekly\" src=\"https://external-preview.redd.it/5PSsVQ_3XxRR2Og2T2fx8tVD7sB7_Rej-3xtzE_9hIc.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3c9061693f05bd6bf9d197c3d4b31f4c816fb578\" title=\"OpenAI says over a million people talk to ChatGPT about suicide weekly\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MetaKnowing\"> /u/MetaKnowing </a> <br /> <span><a href=\"https://techcrunch.com/2025/10/27/openai-says-over-a-million-people-talk-to-chatgpt-about-suicide-weekly/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/artificial/comments/1oi5ove/openai_says_over_a_million_people_talk_to_chatgpt/\">[comments]</a></span> </td></tr></table>",
    "published": "2025-10-28T10:27:11+00:00",
    "source_name": "reddit_ai",
    "source_url": "https://www.reddit.com/r/artificial/hot.rss?limit=10",
    "category": "community_discussion",
    "weight": 0.7,
    "ai_relevance_score": 1.0,
    "timestamp": "2025-10-28T09:00:07.889338",
    "ready_for_mytribal": true,
    "parsed_date": "2025-10-28T10:27:11+00:00",
    "days_old": 0,
    "priority_score": 1.0499999999999998
  },
  {
    "title": "Amazon to cut 30,000 jobs worldwide as workers to be replaced with AI",
    "link": "https://www.reddit.com/r/artificial/comments/1oi8a0g/amazon_to_cut_30000_jobs_worldwide_as_workers_to/",
    "summary": "<table> <tr><td> <a href=\"https://www.reddit.com/r/artificial/comments/1oi8a0g/amazon_to_cut_30000_jobs_worldwide_as_workers_to/\"> <img alt=\"Amazon to cut 30,000 jobs worldwide as workers to be replaced with AI\" src=\"https://external-preview.redd.it/LsTZ5uF1jml2avlJ3CNbYtA6oHJOIkDq7FutaYnPe6U.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4b08b8d3b1df24da42afcbc4ee456858e9ca00e2\" title=\"Amazon to cut 30,000 jobs worldwide as workers to be replaced with AI\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TheMirrorUS\"> /u/TheMirrorUS </a> <br /> <span><a href=\"https://www.themirror.com/news/world-news/amazon-cuts-jobs-ai-takeover-1470952\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/artificial/comments/1oi8a0g/amazon_to_cut_30000_jobs_worldwide_as_workers_to/\">[comments]</a></span> </td></tr></table>",
    "published": "2025-10-28T12:40:53+00:00",
    "source_name": "reddit_ai",
    "source_url": "https://www.reddit.com/r/artificial/hot.rss?limit=10",
    "category": "community_discussion",
    "weight": 0.7,
    "ai_relevance_score": 0.6,
    "timestamp": "2025-10-28T09:00:07.889443",
    "ready_for_mytribal": true,
    "parsed_date": "2025-10-28T12:40:53+00:00",
    "days_old": 0,
    "priority_score": 0.63
  },
  {
    "title": "Anthropic has launched financial services.",
    "link": "https://www.reddit.com/r/artificial/comments/1ohttca/anthropic_has_launched_financial_services/",
    "summary": "<table> <tr><td> <a href=\"https://www.reddit.com/r/artificial/comments/1ohttca/anthropic_has_launched_financial_services/\"> <img alt=\"Anthropic has launched financial services.\" src=\"https://external-preview.redd.it/2KZMtNp3ZSjA6emvV-BRBoPROqKa2bmF5zyl8tnNIzk.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c0b44aa638f6fe8e27e84e1e6db63e5eedfa5063\" title=\"Anthropic has launched financial services.\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Featuring capabilities such as Excel plugins, real-time market data connectors, and portfolio analysis tools, it also comes with built-in professional skills like pre-set discounted cash flow modeling and first-over report generation. It ranked first in the Vals AI Financial Agent Benchmark Test with an accuracy of 55.3%. The goal is to integrate artificial intelligence into key financial workflows.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/zshm\"> /u/zshm </a> <br /> <span><a href=\"https://www.anthropic.com/news/advancing-claude-for-financial-services\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/artificial/comments/1ohttca/anthropic_has_launched_financial_services/\">[comments]</a></span> </td></tr></table>",
    "published": "2025-10-27T23:18:04+00:00",
    "source_name": "reddit_ai",
    "source_url": "https://www.reddit.com/r/artificial/hot.rss?limit=10",
    "category": "community_discussion",
    "weight": 0.7,
    "ai_relevance_score": 0.6,
    "timestamp": "2025-10-28T09:00:07.889532",
    "ready_for_mytribal": true,
    "parsed_date": "2025-10-27T23:18:04+00:00",
    "days_old": 0,
    "priority_score": 0.63
  },
  {
    "title": "PayPal strikes deal to enable payments in ChatGPT and create an AI shopping assistant",
    "link": "https://www.reddit.com/r/artificial/comments/1oibje9/paypal_strikes_deal_to_enable_payments_in_chatgpt/",
    "summary": "<table> <tr><td> <a href=\"https://www.reddit.com/r/artificial/comments/1oibje9/paypal_strikes_deal_to_enable_payments_in_chatgpt/\"> <img alt=\"PayPal strikes deal to enable payments in ChatGPT and create an AI shopping assistant\" src=\"https://external-preview.redd.it/NtlNeT9N9jSNWRVAW1epcxCGa9O3iPCLSI8OOAHBAto.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fbc0930268c97865f6538c02ed99df427fc29b2a\" title=\"PayPal strikes deal to enable payments in ChatGPT and create an AI shopping assistant\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Tiny-Independent273\"> /u/Tiny-Independent273 </a> <br /> <span><a href=\"https://www.pcguide.com/news/paypal-strikes-deal-to-enable-payments-in-chatgpt-and-create-an-ai-shopping-assistant/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/artificial/comments/1oibje9/paypal_strikes_deal_to_enable_payments_in_chatgpt/\">[comments]</a></span> </td></tr></table>",
    "published": "2025-10-28T14:54:02+00:00",
    "source_name": "reddit_ai",
    "source_url": "https://www.reddit.com/r/artificial/hot.rss?limit=10",
    "category": "community_discussion",
    "weight": 0.7,
    "ai_relevance_score": 0.8,
    "timestamp": "2025-10-28T09:00:07.889684",
    "ready_for_mytribal": true,
    "parsed_date": "2025-10-28T14:54:02+00:00",
    "days_old": 0,
    "priority_score": 0.8399999999999999
  },
  {
    "title": "Bernie says OpenAI should be broken up: \"AI like a meteor coming\" ... He's worried about 1) \"massive loss of jobs\" 2) what it does to us as human beings 3) \"Terminator scenarios\" where superintelligent AI takes over.",
    "link": "https://www.reddit.com/r/artificial/comments/1ohd9d6/bernie_says_openai_should_be_broken_up_ai_like_a/",
    "summary": "<table> <tr><td> <a href=\"https://www.reddit.com/r/artificial/comments/1ohd9d6/bernie_says_openai_should_be_broken_up_ai_like_a/\"> <img alt=\"Bernie says OpenAI should be broken up: &quot;AI like a meteor coming&quot; ... He's worried about 1) &quot;massive loss of jobs&quot; 2) what it does to us as human beings 3) &quot;Terminator scenarios&quot; where superintelligent AI takes over.\" src=\"https://external-preview.redd.it/ODdvMDFrczFnbnhmMTI7WrO6YVl8GGpFyQBecvu6jlhqeH6sCJaL-3tqfCvo.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fc302e8dcd45b034ec7b9b84b72271d2ad7e07a3\" title=\"Bernie says OpenAI should be broken up: &quot;AI like a meteor coming&quot; ... He's worried about 1) &quot;massive loss of jobs&quot; 2) what it does to us as human beings 3) &quot;Terminator scenarios&quot; where superintelligent AI takes over.\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MetaKnowing\"> /u/MetaKnowing </a> <br /> <span><a href=\"https://v.redd.it/g90epks1gnxf1\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/artificial/comments/1ohd9d6/bernie_says_openai_should_be_broken_up_ai_like_a/\">[comments]</a></span> </td></tr></table>",
    "published": "2025-10-27T12:38:18+00:00",
    "source_name": "reddit_ai",
    "source_url": "https://www.reddit.com/r/artificial/hot.rss?limit=10",
    "category": "community_discussion",
    "weight": 0.7,
    "ai_relevance_score": 0.8,
    "timestamp": "2025-10-28T09:00:07.889805",
    "ready_for_mytribal": true,
    "parsed_date": "2025-10-27T12:38:18+00:00",
    "days_old": 1,
    "priority_score": 0.8399999999999999
  },
  {
    "title": "Adobe MAX 2025: All the Top Announcements for Adobe’s Creative Suite",
    "link": "https://www.wired.com/story/adobe-max-2025-firefly-photoshop-updates/",
    "summary": "At Adobe’s annual MAX conference, the company also teased a ChatGPT integration and a new AI assistant in Photoshop.",
    "published": "Tue, 28 Oct 2025 12:00:00 +0000",
    "source_name": "wired_ai",
    "source_url": "https://www.wired.com/feed/rss",
    "category": "tech_news",
    "weight": 0.85,
    "ai_relevance_score": 0.6,
    "timestamp": "2025-10-28T09:00:10.282552",
    "ready_for_mytribal": true,
    "parsed_date": null,
    "days_old": 999,
    "priority_score": 0.51
  }
]